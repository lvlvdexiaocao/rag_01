import streamlit as st
import pandas as pd
# from ragas.embeddings import BaseRagasEmbeddings
# from ragas.llms import BaseRagasLLM
# from zhipuai import ZhipuAI


st.set_page_config(
    page_title="RAGAS è¯„ä¼°ç»“æœå¯è§†åŒ–åº”ç”¨",
    layout="wide",
    initial_sidebar_state="expanded"
)

# ====== ä¾§è¾¹æ  ======
with st.sidebar:
    st.header("ğŸ”‘ API ä¸æ¨¡å‹é€‰æ‹©")

    api_key = st.text_input("è¯·è¾“å…¥ OpenAI API Key", type="password")

    model = st.selectbox(
        "é€‰æ‹©æ¨¡å‹",
        ["glm-4.6"],
        index=0
    )
    st.markdown("---")

    st.subheader("ä¸Šä¼ è¯„ä¼°ç»“æœæ–‡ä»¶ (Excel/CSV)")
    uploaded_file = st.file_uploader(
        "Drag and drop file here\nLimit 200MB per file â€¢ XLSX, CSV",
        type=["xlsx", "csv"],
        accept_multiple_files=False
    )

    if uploaded_file:
        st.info(f"ğŸ“ {uploaded_file.name} ({uploaded_file.size // 1024} KB)")

# ====== ä¸»é¡µé¢ ======
st.title("ğŸ“Š RAGAS è¯„ä¼°ç»“æœå¯è§†åŒ–åº”ç”¨ (å¸¦æˆæƒ)")

# è¯»å–æ•°æ®ï¼ˆä»…ç”¨äºå±•ç¤ºï¼Œä¸å¤„ç†ï¼‰
df = None
row_count = 0
if uploaded_file:
    try:
        if uploaded_file.name.endswith(".csv"):
            df = pd.read_csv(uploaded_file)
        else:
            df = pd.read_excel(uploaded_file)
        row_count = len(df)
    except Exception as e:
        st.error(f"âŒ æ–‡ä»¶è¯»å–å¤±è´¥ï¼š{e}")

st.write(f"å·²è¯»å–æ•°æ®è¡Œæ•°: **{row_count}**")

# ====== åŸå§‹æ•°æ®è¡¨ ======
st.subheader("ğŸ“ åŸå§‹æ•°æ®è¡¨")

# åˆ—è¯´æ˜ï¼ˆå’Œè§†é¢‘ä¸€è‡´ï¼‰
with st.expander("æŸ¥çœ‹è¯´æ˜"):
    col_names = ["question", "contexts", "answer", "ground_truth"]
    chinese_names = ["åŸå§‹é—®é¢˜", "ä¸Šä¸‹æ–‡", "ç”Ÿæˆå›ç­”", "æ ‡å‡†ç­”æ¡ˆ"]
    metrics_desc = [
        "Answer Relevance; Context Precision",
        "Faithfulness; Context Precision; Context Recall",
        "Faithfulness; Answer Relevance; Answer Semantic Similarity; Answer Correctness",
        "Context Recall; Answer Semantic Similarity; Answer Correctness"
    ]

    cols = st.columns(len(col_names))
    for i, col in enumerate(cols):
        with col:
            st.markdown(f"**{col_names[i]}**")
            st.caption(chinese_names[i])
            st.caption(metrics_desc[i])

with st.expander("æŸ¥çœ‹ä¼ å…¥æ–‡ä»¶"):
    if df is not None:
        # åªæ˜¾ç¤ºå‰ 5 è¡Œï¼ˆå¯è°ƒæ•´ï¼‰
        display_rows = min(5, len(df))

        st.subheader(f"ğŸ“„ é¢„è§ˆå‰ {display_rows} æ¡æ•°æ®")

        for idx in range(display_rows):
            row = df.iloc[idx]

            # åˆ›å»ºå››åˆ—
            cols = st.columns(4)

            # question
            with cols[0]:
                st.markdown("**â“ é—®é¢˜**")
                st.markdown(f"<div style='font-size: 0.9em; line-height: 1.6;'>{row.get('question', '')}</div>", unsafe_allow_html=True)

            # contexts
            with cols[1]:
                st.markdown("**ğŸ“š ä¸Šä¸‹æ–‡**")
                ctx_text = row.get('contexts', '')
                if isinstance(ctx_text, list):
                    ctx_text = "\n\n".join(ctx_text)
                st.markdown(f"<div style='font-size: 0.9em; line-height: 1.6;'>{ctx_text}</div>", unsafe_allow_html=True)

            # answer
            with cols[2]:
                st.markdown("**ğŸ’¬ å›ç­”**")
                ans_text = row.get('answer', '')
                st.markdown(f"<div style='font-size: 0.9em; line-height: 1.6;'>{ans_text}</div>", unsafe_allow_html=True)

            # ground_truth
            with cols[3]:
                st.markdown("**âœ… æ ‡å‡†ç­”æ¡ˆ**")
                gt_text = row.get('ground_truth', '')
                st.markdown(f"<div style='font-size: 0.9em; line-height: 1.6;'>{gt_text}</div>", unsafe_allow_html=True)

            # åˆ†éš”çº¿
            st.markdown("---")

    else:
        st.info("è¯·ä¸Šä¼  CSV æˆ– Excel æ–‡ä»¶ä»¥é¢„è§ˆæ•°æ®ã€‚")


# ====== RAGAS è‡ªåŠ¨è¯„ä¼°åŒºåŸŸ ======
st.subheader("ğŸ¤– RAGAS è‡ªåŠ¨è¯„ä¼°")

start_eval = st.button("ğŸš€ å¼€å§‹RAGASè¯„ä¼°", type="primary", key="start_eval_btn")
gen_report = st.checkbox("ğŸ“„ ç”ŸæˆLLMæ–‡æœ¬æŠ¥å‘Š", key="gen_report_checkbox")

if "ragas_result" not in st.session_state:
    st.session_state.ragas_result = None

if start_eval:
    if df is None:
        st.error("âŒ è¯·å…ˆä¸Šä¼ æœ‰æ•ˆçš„æµ‹è¯•æ•°æ®æ–‡ä»¶ã€‚")
    elif not api_key:
        st.error("âŒ è¯·åœ¨å·¦ä¾§è¾¹æ è¾“å…¥ OpenAI API Keyã€‚")
    else:
        try:
            with st.spinner("â³ æ­£åœ¨è¿è¡Œ RAGAS è¯„ä¼°ï¼ˆå¯èƒ½éœ€è¦ 1-2 åˆ†é’Ÿï¼‰..."):
                # è°ƒç”¨ä½ æä¾›çš„å‡½æ•°
                result_df = run_ragas_evaluation(df, model_name=model, api_key=api_key)
                st.session_state.ragas_result = result_df
        except Exception as e:
            st.error(f"âŒ è¯„ä¼°å‡ºé”™ï¼š{e}")
            st.session_state.ragas_result = None

# æ˜¾ç¤ºè¯„ä¼°ç»“æœï¼ˆå¦‚æœå­˜åœ¨ï¼‰
if st.session_state.ragas_result is not None:
    result_df = st.session_state.ragas_result

    # æ˜¾ç¤ºå¹³å‡åˆ†
    metric_cols = [col for col in result_df.columns if col not in ['question', 'answer', 'contexts', 'ground_truth']]
    if metric_cols:
        avg_scores = result_df[metric_cols].mean()
        st.subheader("ğŸ“ˆ å¹³å‡æŒ‡æ ‡å¾—åˆ†")
        cols = st.columns(len(metric_cols))
        for i, col in enumerate(metric_cols):
            cols[i].metric(col, f"{avg_scores[col]:.3f}")

    # æ˜¾ç¤ºå®Œæ•´ç»“æœè¡¨æ ¼
    st.subheader("ğŸ“‹ è¯¦ç»†è¯„ä¼°ç»“æœ")
    st.dataframe(result_df, width="stretch", height=500)
    from datetime import datetime

    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    file_name = f"ragas_result_{timestamp}.csv"
    # ====== æ–°å¢ï¼šä¸‹è½½æŒ‰é’® ======
    st.subheader("ğŸ’¾ å¯¼å‡ºè¯„ä¼°ç»“æœ")
    csv = result_df.to_csv(index=False).encode('utf-8')
    st.download_button(
        label="â¬‡ï¸ ä¸‹è½½ CSV æ–‡ä»¶",
        data=csv,
        file_name=file_name,
        mime="text/csv",
        key="download-csv"
    )
    # å¯é€‰ï¼šç”ŸæˆæŠ¥å‘Šï¼ˆç•™æ¥å£ï¼‰
    if gen_report:
        st.info("ğŸ“ LLM æ–‡æœ¬æŠ¥å‘ŠåŠŸèƒ½å¾…å®ç°ï¼ˆå¯è°ƒç”¨ LLM æ€»ç»“æŒ‡æ ‡ï¼‰")
else:
    st.info("è¯·ç‚¹å‡»ä¸Šæ–¹æŒ‰é’®å¼€å§‹RAGASè¯„ä¼°ã€‚")


